{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pythorch Challenge: Labtest.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7uGa1v8zhrCt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Developing an AI application **\n",
        "\n",
        "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications.\n",
        "\n",
        "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using this dataset of 102 flower categories, you can see a few examples below.\n",
        "\n",
        "The project is broken down into multiple steps:\n",
        "\n",
        "* Load and preprocess the image dataset\n",
        "* Train the image classifier on your dataset\n",
        "* Use the trained classifier to predict image content\n",
        "* We'll lead you through each part which you'll implement in Python.\n",
        "\n",
        "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
        "\n",
        "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."
      ]
    },
    {
      "metadata": {
        "id": "8v6zW6Gc7_mf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# google colab does not come with torch installed. And also, in course we are using torch 0.4. \n",
        "# so following snippet of code installs the relevant version\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zu3Nb4G28PhF",
        "colab_type": "code",
        "outputId": "728af9b5-44e5-420b-a140-e840dd477932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "# \n",
        "# if it prints otherwise, then you need to enable GPU: \n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lYfcICFm8diE",
        "colab_type": "code",
        "outputId": "955c92d8-161a-44e1-ce83-7c94c7edfca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "cell_type": "code",
      "source": [
        "# we need pillow version of 5.3.0\n",
        "# we will uninstall the older version first\n",
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "# this should print 5.3.0. If it doesn't, then restart your runtime:\n",
        "# Menu > Runtime > Restart Runtime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-5.3.0:\n",
            "  Successfully uninstalled Pillow-5.3.0\n",
            "Collecting Pillow==5.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n",
            "5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qr8qlHg98rlu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tl_gbi4DoBD5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Load the data **\n",
        "\n",
        "Here you'll use torchvision to load the data (documentation). You can download the data here. The dataset is split into two parts, training and validation. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. If you use a pre-trained network, you'll also need to make sure the input data is resized to 224x224 pixels as required by the networks.\n",
        "\n",
        "The validation set is used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size."
      ]
    },
    {
      "metadata": {
        "id": "BVRAtwGx8zAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we will download the required data files\n",
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "!rm -r flower_data || true\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nxzqw8K99NLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = './flower_data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZtY4opa9bYm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "\n",
        "#train_data = datasets.ImageFolder(train_dir, transform = train_transforms)\n",
        "#validation_data = datasets.ImageFolder(valid_dir, transform = validation_transforms)\n",
        "dirs = {'train': train_dir, \n",
        "        'valid': valid_dir}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(dirs[x], transform=data_transforms[x]) for x in ['train', 'valid']}\n",
        "\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "#train_loader = torch.utils.data.DataLoader(train_data, batch_size = 32, shuffle = True)\n",
        "#validation_loader = torch.utils.data.DataLoader(validation_data, batch_size = 32, shuffle = True)\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) \n",
        "               for x in ['train', 'valid']}\n",
        "\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
        "class_names = image_datasets['train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tP0-4QC9oMRz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Label mapping  **\n",
        "\n",
        "You'll also need to load in a mapping from category label to category name. You can find this in the file cat_to_name.json. It's a JSON object which you can read in with the json module. This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
      ]
    },
    {
      "metadata": {
        "id": "IZ5fob-0N4EA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axP6d9NxOA6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Build and train your network\n",
        "model = models.vgg19(pretrained = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8bTu5QVZOMNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Custom classifier to replace vgg19 classifier\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(25088, 4096)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(4096, 102)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3KRsQR5MOQt6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Stop updating of pre-trained models\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "    \n",
        "# Replace vgg19 classifier with custom classifier\n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qCXfs4_AOfZq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Model\n",
        "\n",
        "def training_model(model, criteria, optimizer, scheduler, epochs = 30):\n",
        "    \n",
        "    \n",
        "    \n",
        "    #wts_best_model = copy.deepcopy(model.state.dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    model.to(device)\n",
        "    \n",
        "    for e in range(epochs):\n",
        "        print('Epoch {}/{}'.format(e + 1, epochs))\n",
        "        print('-' * 12)\n",
        "        \n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "                \n",
        "            running_loss = 0.0\n",
        "            correct_predictions = 0\n",
        "            \n",
        "            # Iterate over data\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # Clear parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                #forward propagation\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    \n",
        "                    #backward propagation and optimization\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                # Calculate Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                correct_predictions += torch.sum(preds == labels.data)\n",
        "                \n",
        "            \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = correct_predictions.double() / dataset_sizes[phase]\n",
        "            \n",
        "            \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # save deep model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                wts_best_model = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        print()\n",
        "        \n",
        "    print('Best val Acc: %d%%' %(best_acc * 100))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(wts_best_model)\n",
        "        \n",
        "    return model\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "et58MEg0Oh3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "# Criteria for Softmax final layer \n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "#Optimizer\n",
        "#optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
        "optimizer = optim.SGD(model.classifier.parameters(), lr = 0.01, momentum=0.9)\n",
        "\n",
        "# Learning rate decay\n",
        "sched = lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.1)\n",
        "\n",
        "# Number of Epochs\n",
        "\n",
        "eps = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9-B0HKYPHRo",
        "colab_type": "code",
        "outputId": "5f25128a-497f-433f-8315-4a18c4bf5aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1334
        }
      },
      "cell_type": "code",
      "source": [
        "train_model = training_model(model, criterion, optimizer, sched, eps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "------------\n",
            "train Loss: 2.3998 Acc: 0.4245\n",
            "valid Loss: 1.2692 Acc: 0.6760\n",
            "\n",
            "Epoch 2/15\n",
            "------------\n",
            "train Loss: 1.3570 Acc: 0.6358\n",
            "valid Loss: 0.8938 Acc: 0.7396\n",
            "\n",
            "Epoch 3/15\n",
            "------------\n",
            "train Loss: 1.1165 Acc: 0.6944\n",
            "valid Loss: 0.8468 Acc: 0.7800\n",
            "\n",
            "Epoch 4/15\n",
            "------------\n",
            "train Loss: 1.0121 Acc: 0.7300\n",
            "valid Loss: 0.7781 Acc: 0.8227\n",
            "\n",
            "Epoch 5/15\n",
            "------------\n",
            "train Loss: 0.9505 Acc: 0.7494\n",
            "valid Loss: 0.6920 Acc: 0.8240\n",
            "\n",
            "Epoch 6/15\n",
            "------------\n",
            "train Loss: 0.6037 Acc: 0.8367\n",
            "valid Loss: 0.4319 Acc: 0.8814\n",
            "\n",
            "Epoch 7/15\n",
            "------------\n",
            "train Loss: 0.5112 Acc: 0.8576\n",
            "valid Loss: 0.4013 Acc: 0.8961\n",
            "\n",
            "Epoch 8/15\n",
            "------------\n",
            "train Loss: 0.4818 Acc: 0.8684\n",
            "valid Loss: 0.3820 Acc: 0.8973\n",
            "\n",
            "Epoch 9/15\n",
            "------------\n",
            "train Loss: 0.4314 Acc: 0.8777\n",
            "valid Loss: 0.3606 Acc: 0.9010\n",
            "\n",
            "Epoch 10/15\n",
            "------------\n",
            "train Loss: 0.4323 Acc: 0.8794\n",
            "valid Loss: 0.3656 Acc: 0.9010\n",
            "\n",
            "Epoch 11/15\n",
            "------------\n",
            "train Loss: 0.4090 Acc: 0.8829\n",
            "valid Loss: 0.3524 Acc: 0.9034\n",
            "\n",
            "Epoch 12/15\n",
            "------------\n",
            "train Loss: 0.3804 Acc: 0.8926\n",
            "valid Loss: 0.3449 Acc: 0.9083\n",
            "\n",
            "Epoch 13/15\n",
            "------------\n",
            "train Loss: 0.4026 Acc: 0.8903\n",
            "valid Loss: 0.3378 Acc: 0.9144\n",
            "\n",
            "Epoch 14/15\n",
            "------------\n",
            "train Loss: 0.3933 Acc: 0.8858\n",
            "valid Loss: 0.3371 Acc: 0.9095\n",
            "\n",
            "Epoch 15/15\n",
            "------------\n",
            "train Loss: 0.4025 Acc: 0.8823\n",
            "valid Loss: 0.3397 Acc: 0.9071\n",
            "\n",
            "Best val Acc: 91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wI66FZrAquMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Save the checkpoint \n",
        "\n",
        "model.class_to_idx = image_datasets['train'].class_to_idx\n",
        "model.cpu()\n",
        "\n",
        "torch.save({\n",
        "            'structure': 'vgg19',\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer.state_dict': optimizer.state_dict(),\n",
        "            'epoch': eps,\n",
        "            'class_to_idx': model.class_to_idx}, 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1gGSuBRJq3qc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
        "\n",
        "def load_model(path):\n",
        "    checkpoint = torch.load(path)\n",
        "    \n",
        "    model = models.vgg19(pretrained = True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    model.class_to_idx = checkpoint['class_to_idx']\n",
        "    \n",
        "    # Classifier\n",
        "    classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(25088, 4096)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(4096, 102)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "    model.classifier = classifier\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3KNPldoq-70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "    \n",
        "    # TODO: Process a PIL image for use in a PyTorch model\n",
        "    \n",
        "    #Open image\n",
        "    img = Image.open(image)\n",
        "    \n",
        "    #Image Transformation\n",
        "    img_transformation = transforms.Compose([\n",
        "                                        transforms.Resize(256),\n",
        "                                        transforms.CenterCrop(224),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                    ])\n",
        "    \n",
        "    img = img_transformation(img)\n",
        "    \n",
        "    return img\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-2OYjmiHueJ4",
        "colab_type": "code",
        "outputId": "029cf766-ca0c-400a-c7d0-769295907c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}